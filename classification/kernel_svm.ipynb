{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI2VXX/Ry8JVEe/dH39plf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/classification/kernel_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                                      | Description                                                                                                          |\n",
        "|-----------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n",
        "| **Training the Kernel SVM model on the Training set**     | Build a Support Vector Machine (SVM) classifier with a non-linear kernel using the training set (`X_train` and `y_train`).   |\n",
        "|                                                           | The `SVC` class from scikit-learn is used to create the classifier.                                                  |\n",
        "|                                                           | Set `kernel='rbf'` to use the Radial Basis Function (RBF) kernel, which allows for non-linear separation.                |\n",
        "|                                                           | Set `random_state=0` for reproducibility of results.                                                                 |\n",
        "|                                                           | Train the SVM classifier on the training data to learn the relationships between the independent variables (`X_train`) and the binary dependent variable (`y_train`). |\n",
        "| **Predicting a new result**                               | Use the trained classifier to predict the outcome for a new sample.                                                    |\n",
        "|                                                           | For example, the code predicts the outcome for the new sample `[30, 87000]`.                                          |\n",
        "|                                                           | The new sample `[30, 87000]` is scaled using the same scaling applied during training (`sc.transform`), as the classifier was trained on scaled data. |\n",
        "| **Predicting the Test set results**                       | Use the trained classifier to predict outcomes for the test set (`X_test`).                                            |\n",
        "|                                                           | The predicted outcomes for the test set are stored in `y_pred`.                                                       |\n",
        "| **Making the Confusion Matrix**                           | Create a confusion matrix to compare the actual outcomes (from `y_test`) with the predicted outcomes (from `y_pred`).   |\n",
        "|                                                           | The `confusion_matrix` function from scikit-learn is used for this purpose.                                            |\n",
        "| **Calculating the Accuracy Score**                        | Calculate the accuracy of the classifier on the test set using the `accuracy_score` function from scikit-learn.      |\n",
        "|                                                           | The accuracy score is the proportion of correctly predicted outcomes compared to the total number of test samples.   |\n",
        "| **Visualising the Test set results**                      | To visualize the classifier's decision boundary, create a grid of points covering the feature space (`X1`, `X2`).   |\n",
        "|                                                           | Predict the class labels for each point in the grid using the trained classifier.                                    |\n",
        "|                                                           | Use `plt.contourf()` to create filled contours to represent the decision boundary. Different colors represent different classes ('salmon' and 'dodgerblue'). |\n",
        "|                                                           | Plot the actual data points in the test set (`X_set`, `y_set`) with the colors corresponding to their respective classes. |\n",
        "|                                                           | The resulting plot shows how the Kernel SVM classifier separates the two classes based on the features 'Age' and 'Estimated Salary'. |\n"
      ],
      "metadata": {
        "id": "AsrJUJFkt-_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training the Kernel SVM model on the Training set\n",
        "classifier = SVC(kernel='rbf', random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting a new result\n",
        "new_sample = sc.transform([[30, 87000]])\n",
        "print(classifier.predict(new_sample))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Calculating the Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "# Visualising the Test set results\n",
        "X_set, y_set = sc.inverse_transform(X_test), y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 10, stop=X_set[:, 0].max() + 10, step=0.25),\n",
        "                     np.arange(start=X_set[:, 1].min() - 1000, stop=X_set[:, 1].max() + 1000, step=0.25))\n",
        "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
        "             alpha=0.75, cmap=ListedColormap(('salmon', 'dodgerblue')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c=ListedColormap(('salmon', 'dodgerblue'))(i), label=j)\n",
        "plt.title('Kernel SVM (Test set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZntZ76rE0PW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}