{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiGcU+0m3PlqTImy3/kMhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/deep_learning/artificial_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                           | Description                                                                                                                                         |\n",
        "|------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Importing the libraries                       | Import the required libraries, including NumPy, Pandas, and TensorFlow. These libraries provide essential tools for working with data and building neural networks. |\n",
        "| Importing the dataset                         | Load the dataset into variables. The dataset should contain the input features (X) and the corresponding target labels (y) for both the training and test sets. |\n",
        "| Encoding categorical data (if required)        | If the dataset contains categorical data that needs encoding, apply techniques like one-hot encoding to convert categorical variables into numerical format. |\n",
        "| Splitting the dataset into the Training set and Test set | Divide the dataset into two parts: the training set (used to train the model) and the test set (used to evaluate the model's performance on unseen data). |\n",
        "| Feature Scaling                                | Scale the feature values to ensure that all input features have the same scale. Feature scaling helps the model converge faster and prevents some features from dominating others. |\n",
        "| Initializing the ANN                          | Create an instance of the Sequential class from Keras to initialize an empty ANN model. The Sequential class allows us to build a neural network layer by layer. |\n",
        "| Adding the input layer and the first hidden layer | Add the input layer to the model, specifying the number of units (neurons) and the activation function to be used for the first hidden layer. The activation function introduces non-linearity into the model. |\n",
        "| Adding the second hidden layer                 | Add the second hidden layer with the same number of units and activation function as the first hidden layer. Multiple hidden layers allow the model to learn complex patterns in the data. |\n",
        "| Adding the output layer                        | Add the output layer to the model with one unit (for binary classification) and a sigmoid activation function. The sigmoid activation function outputs probabilities between 0 and 1, making it suitable for binary classification. |\n",
        "| Compiling the ANN                             | Compile the model by specifying the optimizer, loss function, and evaluation metrics. The optimizer updates the model's weights during training, the loss function measures the model's performance, and the evaluation metrics provide additional metrics for evaluation. |\n",
        "| Training the ANN on the Training set           | Train the ANN model on the training set using the `fit` method. During training, the model adjusts its weights to minimize the chosen loss function and improve performance on the training data. |\n",
        "| Predicting the Test set results                | Use the trained model to predict the target labels (y_pred) for the test set. The model makes predictions based on the input features (X_test). |\n",
        "| Making the Confusion Matrix                    | Evaluate the performance of the trained ANN model on the test set by creating a confusion matrix. The confusion matrix shows the number of correct and incorrect predictions for each class, allowing us to assess the model's accuracy and other performance metrics. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "\n",
        "# Importing the dataset\n",
        "# Assuming you have already loaded the dataset into X_train, y_train, X_test, and y_test\n",
        "\n",
        "# Encoding categorical data (if required)\n",
        "# Assuming the dataset does not contain categorical data that needs encoding\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set (if required)\n",
        "# Assuming you have already split the dataset\n",
        "\n",
        "# Feature Scaling\n",
        "# Assuming you have already performed feature scaling on X_train and X_test\n",
        "\n",
        "# Initializing the ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the ANN on the Training set\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs=100)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "# Assuming you have already imported and defined the confusion_matrix function from scikit-learn\n",
        "# And you have used it to create the confusion matrix\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}