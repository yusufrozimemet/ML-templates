{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdGqLE1MESxETaTm0N6s/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/deep_learning/Boltzmann_Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step Name                                              | Description                                                                                                 |\n",
        "|--------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
        "| Downloading the Dataset                               | This step involves downloading the MovieLens datasets (ml-100k and ml-1m) from the provided URLs and extracting them. |\n",
        "| Importing the Libraries                               | The necessary libraries (NumPy, Pandas, Torch) are imported for data manipulation and building the neural network. |\n",
        "| Importing the Dataset                                 | The MovieLens datasets (movies, users, ratings) are imported using Pandas, but these datasets won't be used in this specific code. |\n",
        "| Preparing the Training Set and Test Set               | The training and test sets are loaded from the files \"u1.base\" and \"u1.test\" in the ml-100k dataset, respectively. |\n",
        "| Getting the Number of Users and Movies                | The total number of users and movies are calculated to determine the dimensions of the user-movie interaction matrix. |\n",
        "| Converting the Data into an Array with Users in Lines and Movies in Columns | The training and test sets are converted into a list of lists where each list corresponds to a user's ratings for all movies. |\n",
        "| Converting the Data into Torch Tensors                | The user-movie interaction matrices (training and test sets) are converted into Torch tensors, which are used in PyTorch for building neural networks. |\n",
        "| Converting the Ratings into Binary Ratings 1 (Liked) or 0 (Not Liked) | The original ratings are converted into binary ratings. Ratings below 3 are considered as \"Not Liked\" (0), and ratings of 3 and above are considered as \"Liked\" (1). |\n",
        "| Creating the Architecture of the Neural Network (Restricted Boltzmann Machine) | A class RBM is defined, which represents the Restricted Boltzmann Machine. It initializes random weights and biases, and contains methods for sampling hidden and visible units and updating the model during training. |\n",
        "| Training the RBM                                      | The RBM model is trained using the Contrastive Divergence (CD) algorithm with the training set. |\n",
        "| Testing the RBM                                       | The trained RBM model is tested using the test set to evaluate its performance. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset\n",
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "!unzip ml-100k.zip\n",
        "!ls\n",
        "\n",
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "!unzip ml-1m.zip\n",
        "!ls\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Importing the dataset\n",
        "# We won't be using this dataset.\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
        "\n",
        "# Preparing the training set and the test set\n",
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
        "test_set = np.array(test_set, dtype='int')\n",
        "\n",
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
        "\n",
        "# Converting the data into an array with users in lines and movies in columns\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "# Converting the data into Torch tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)\n",
        "\n",
        "# Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1\n",
        "\n",
        "# Creating the architecture of the Neural Network\n",
        "class RBM():\n",
        "    def __init__(self, nv, nh):\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        self.a = torch.randn(1, nh)\n",
        "        self.b = torch.randn(1, nv)\n",
        "\n",
        "    def sample_h(self, x):\n",
        "        wx = torch.mm(x, self.W.t())\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        p_h_given_v = torch.sigmoid(activation)\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "\n",
        "    def sample_v(self, y):\n",
        "        wy = torch.mm(y, self.W)\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        p_v_given_h = torch.sigmoid(activation)\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "\n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)\n",
        "\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)\n",
        "\n",
        "# Training the RBM\n",
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user: id_user + batch_size]\n",
        "        v0 = training_set[id_user: id_user + batch_size]\n",
        "        ph0, _ = rbm.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _, hk = rbm.sample_h(vk)\n",
        "            _, vk = rbm.sample_v(hk)\n",
        "            vk[v0 < 0] = v0[v0 < 0]\n",
        "        phk, _ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
        "        s += 1.\n",
        "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss / s))\n",
        "\n",
        "# Testing the RBM\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user + 1]\n",
        "    vt = test_set[id_user:id_user + 1]\n",
        "    if len(vt[vt >= 0]) > 0:\n",
        "        _, h = rbm.sample_h(v)\n",
        "        _, v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
        "        s += 1.\n",
        "print('test loss: ' + str(test_loss / s))\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}