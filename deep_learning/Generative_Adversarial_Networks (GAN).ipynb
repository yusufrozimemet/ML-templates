{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqnlWhp8gasrUIDk65k2Sc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/deep_learning/Generative_Adversarial_Networks%20(GAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step Name                                          | Description                                                                                             |\n",
        "|----------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
        "| Importing the Dataset                             | Loading the MNIST dataset, which consists of images of handwritten digits (0 to 9).                  |\n",
        "| Filtering out the Data for Faster Training        | Filtering only the images corresponding to digit '0' for faster training on a smaller dataset.       |\n",
        "| Importing necessary libraries                     | Importing the required libraries for building the GAN.                                                |\n",
        "| Setting random seeds for reproducibility          | Setting random seeds to ensure reproducibility of the results.                                        |\n",
        "| Defining the size of input noise vector           | Specifying the size of the input noise vector for the generator.                                      |\n",
        "| Creating the Generator model                      | Defining the generator model architecture using fully connected layers.                               |\n",
        "| Creating the Discriminator model                  | Defining the discriminator model architecture using fully connected layers.                           |\n",
        "| Compiling the Discriminator model                 | Compiling the discriminator model with binary cross-entropy loss and Adam optimizer.                  |\n",
        "| Combining the Generator and Discriminator         | Combining the generator and discriminator models to create the GAN model.                             |\n",
        "| Making the Discriminator not trainable            | Setting the discriminator to be non-trainable in the GAN model.                                       |\n",
        "| Compiling the GAN model                           | Compiling the GAN model with binary cross-entropy loss and Adam optimizer.                             |\n",
        "| Setting up Training Batches                        | Preparing the data in batches for efficient training.                                                 |\n",
        "| Specifying the number of epochs for training       | Specifying the number of epochs to train the GAN.                                                      |\n",
        "| Training Loop                                     | The main training loop for the GAN.                                                                    |\n",
        "| Generating images using the trained Generator      | Generating fake images using the trained Generator.                                                    |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Importing the Dataset\n",
        "# Description: Loading the MNIST dataset, which consists of images of handwritten digits (0 to 9).\n",
        "\n",
        "# Loading MNIST dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Step 2: Filtering out the Data for Faster Training on Smaller Dataset\n",
        "# Description: Filtering out only the images corresponding to digit '0' for faster training on a smaller dataset.\n",
        "\n",
        "# Filtering only the images corresponding to digit '0'\n",
        "only_zeros = X_train[y_train == 0]\n",
        "only_zeros.shape\n",
        "\n",
        "# Step 3: Importing necessary libraries\n",
        "# Description: Importing the required libraries for building the GAN.\n",
        "\n",
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Step 4: Setting random seeds for reproducibility\n",
        "# Description: Setting random seeds to ensure reproducibility of the results.\n",
        "\n",
        "# Setting random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Step 5: Defining the size of input noise vector\n",
        "# Description: Specifying the size of the input noise vector for the generator.\n",
        "\n",
        "# Defining the size of input noise vector\n",
        "codings_size = 100\n",
        "\n",
        "# Step 6: Creating the Generator model\n",
        "# Description: Defining the generator model architecture using fully connected layers.\n",
        "\n",
        "# Creating the Generator model\n",
        "generator = Sequential()\n",
        "generator.add(Dense(100, activation=\"relu\", input_shape=[codings_size]))\n",
        "generator.add(Dense(150, activation='relu'))\n",
        "generator.add(Dense(784, activation=\"sigmoid\"))  # 28*28 = 784\n",
        "generator.add(Reshape([28, 28]))\n",
        "\n",
        "# Step 7: Creating the Discriminator model\n",
        "# Description: Defining the discriminator model architecture using fully connected layers.\n",
        "\n",
        "# Creating the Discriminator model\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Flatten(input_shape=[28, 28]))\n",
        "discriminator.add(Dense(150, activation='relu'))\n",
        "discriminator.add(Dense(100, activation='relu'))\n",
        "discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Step 8: Compiling the Discriminator model\n",
        "# Description: Compiling the discriminator model with binary cross-entropy loss and Adam optimizer.\n",
        "\n",
        "# Compiling the Discriminator model\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Step 9: Combining the Generator and Discriminator to create the GAN model\n",
        "# Description: Combining the generator and discriminator models to create the GAN model.\n",
        "\n",
        "# Combining the Generator and Discriminator to create the GAN model\n",
        "GAN = Sequential([generator, discriminator])\n",
        "\n",
        "# Step 10: Making the Discriminator not trainable in the combined GAN model\n",
        "# Description: Setting the discriminator to be non-trainable in the GAN model.\n",
        "\n",
        "# Making the Discriminator not trainable in the combined GAN model\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Step 11: Compiling the GAN model\n",
        "# Description: Compiling the GAN model with binary cross-entropy loss and Adam optimizer.\n",
        "\n",
        "# Compiling the GAN model\n",
        "GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Step 12: Setting up Training Batches\n",
        "# Description: Preparing the data in batches for efficient training.\n",
        "\n",
        "# Setting the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Using only_zeros dataset for training\n",
        "my_data = only_zeros\n",
        "\n",
        "# Creating TensorFlow Dataset from the filtered dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(my_data).shuffle(buffer_size=1000)\n",
        "\n",
        "# Dividing the dataset into batches and prefetching for efficiency\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "\n",
        "# Step 13: Specifying the number of epochs for training\n",
        "# Description: Specifying the number of epochs to train the GAN.\n",
        "\n",
        "# Specifying the number of epochs for training\n",
        "epochs = 1\n",
        "\n",
        "# Step 14: Training Loop\n",
        "# Description: The main training loop for the GAN.\n",
        "\n",
        "# Grabbing the separate components (Generator and Discriminator) from the GAN model\n",
        "generator, discriminator = GAN.layers\n",
        "\n",
        "# Training loop over multiple epochs\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Currently on Epoch {epoch + 1}\")\n",
        "    i = 0\n",
        "    # For every batch in the dataset\n",
        "    for X_batch in dataset:\n",
        "        i = i + 1\n",
        "        if i % 100 == 0:\n",
        "            print(f\"\\tCurrently on batch number {i} of {len(my_data) // batch_size}\")\n",
        "\n",
        "        # Training the Discriminator\n",
        "        # Creating noise for Generator input\n",
        "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "\n",
        "        # Generating fake images using the Generator\n",
        "        gen_images = generator(noise)\n",
        "\n",
        "        # Concatenating real and fake images to train Discriminator\n",
        "        X_fake_vs_real = tf.concat([gen_images, tf.dtypes.cast(X_batch, tf.float32)], axis=0)\n",
        "\n",
        "        # Setting target labels for Discriminator training\n",
        "        y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "\n",
        "        # Making the Discriminator trainable for this step\n",
        "        discriminator.trainable = True\n",
        "\n",
        "        # Training the Discriminator on the batch\n",
        "        discriminator.train_on_batch(X_fake_vs_real, y1)\n",
        "\n",
        "        # Training the Generator\n",
        "        # Creating new noise for Generator input\n",
        "        noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "\n",
        "        # Setting target labels for Generator training (to fool Discriminator)\n",
        "        y2 = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "        # Making the Discriminator not trainable for this step\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Training the GAN on the batch\n",
        "        GAN.train_on_batch(noise, y2)\n",
        "\n",
        "# Training complete\n",
        "print(\"TRAINING COMPLETE\")\n",
        "\n",
        "# Step 15: Generating images using the trained Generator\n",
        "# Description: Generating fake images using the trained Generator.\n",
        "\n",
        "# Creating noise for Generator input\n",
        "noise = tf.random.normal(shape=[10, codings_size])\n",
        "\n",
        "# Generating fake images using the Generator\n",
        "image = generator(noise)\n",
        "\n",
        "# Displaying one of the generated images\n",
        "plt.imshow(image[5])\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}