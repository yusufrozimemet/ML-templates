{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTKFhTh1yC3c2TwpN/QvPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/deep_learning/summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                                          | Description                                                                                                                            | Use Case                                                                                                                                                       | Pros                                                                                                                                     | Cons                                                                                                                                     |\n",
        "|-----------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| AutoEncoders                                 | Autoencoders are a type of neural network used for unsupervised learning, aiming to reconstruct the input data as output.               | Dimensionality reduction, feature learning, anomaly detection, denoising images, recommendation systems.                                                    | Useful in data compression, can capture important features in the data.                                                                  | May suffer from overfitting, requires a large amount of data to learn meaningful representations.                                        |\n",
        "| Generative_Adversarial_Networks (GAN)        | GANs are a framework of two neural networks (Generator and Discriminator) competing against each other to generate realistic data.     | Image generation, data augmentation, style transfer, super-resolution, video generation.                                                                     | Can produce high-quality synthetic data, used for creative applications.                                                                   | Training instability, mode collapse, requires careful tuning and may not converge.                                                        |\n",
        "| Self Organizing Maps (SOM)                   | SOM is an unsupervised neural network used for dimensionality reduction and visualization of high-dimensional data in lower dimensions. | Data visualization, clustering, pattern recognition, feature extraction.                                                                                  | Useful in visualizing complex data in 2D/3D space, topology preservation.                                                                  | Computationally expensive for large datasets, may require parameter tuning.                                                               |\n",
        "| Boltzmann_Machine                            | Boltzmann Machine is a probabilistic generative model used for unsupervised learning and dimensionality reduction tasks.                | Collaborative filtering, recommendation systems, feature learning, dimensionality reduction.                                                             | Can capture complex dependencies in the data, good for collaborative filtering.                                                            | Training can be slow and computationally expensive, may suffer from overfitting on small datasets.                                       |\n",
        "| artificial_neural_network (ANN)             | ANN is a feedforward neural network that processes input data through layers of interconnected neurons.                              | Classification, regression, pattern recognition, function approximation.                                                                                    | Powerful for non-linear relationships, can handle large datasets.                                                                           | Requires careful tuning of hyperparameters, may suffer from vanishing/exploding gradients.                                               |\n",
        "| convolutional_neural_network (CNN)          | CNN is a specialized neural network designed for image processing tasks by using convolutional layers.                               | Image classification, object detection, image segmentation, facial recognition.                                                                             | Highly effective for image-related tasks, parameter sharing reduces computational burden.                                                   | May require large amounts of data and computation power, may not generalize well on smaller datasets.                                    |\n",
        "| ResNet                                       | ResNet is a deep neural network architecture that uses skip connections (residual blocks) to address vanishing/exploding gradient issues. | Image classification, object detection, image segmentation, transfer learning.                                                                              | Overcomes vanishing/exploding gradient issues, allows training of very deep networks.                                                       | Increased memory usage due to deep architecture, complex to implement without pre-built libraries.                                       |\n",
        "| ResUNet                                      | ResUNet combines the concepts of ResNet and U-Net for semantic segmentation tasks.                                                     | Semantic segmentation, medical image analysis, object detection in images.                                                                                  | Captures fine-grained details, good for segmentation tasks.                                                                                | Complex architecture, requires careful tuning and large datasets.                                                                         |\n",
        "| facebook_prophet                             | Prophet is a time series forecasting model developed by Facebook, designed for business applications.                                  | Time series forecasting, business planning, demand prediction, revenue forecasting.                                                                          | Easy to use, handles missing data and outliers, includes seasonality and holidays.                                                           | May not handle complex time series patterns well, not suitable for tasks with a large number of data points.                             |\n",
        "| Recurrent Neural Networks (RNN)             | RNN is a type of neural network designed for sequential data processing, using feedback loops to process previous outputs.               | Natural language processing, time series forecasting, speech recognition, sentiment analysis.                                                              | Effective for sequence data, handles variable-length inputs, captures temporal dependencies.                                                | May suffer from vanishing/exploding gradients, difficult to parallelize, may not handle long-term dependencies well (LSTM/GRU are better). |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    }
  ]
}