{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOitHPJuHNzfanbKXLgqtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/model_selection/grid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                           | Description                                                                                                      |\n",
        "|------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
        "| Feature Scaling                                | Apply feature scaling to standardize the features in the dataset. Feature scaling ensures that all features have the same scale, which can help improve the performance and convergence of the SVM model. |\n",
        "| Training the Kernel SVM model                  | Train the SVM model with a non-linear kernel (RBF kernel) on the training set. The RBF kernel allows the SVM to handle non-linearly separable data and capture complex relationships between features. |\n",
        "| Making the Confusion Matrix                    | Evaluate the performance of the trained SVM model on the test set by creating a confusion matrix. The confusion matrix shows the number of correct and incorrect predictions for each class. |\n",
        "| Applying k-Fold Cross Validation               | Perform k-Fold Cross Validation to estimate the model's performance on unseen data. The dataset is divided into 'k' subsets (folds), and the model is trained and tested 'k' times, each time using a different fold as the test set and the remaining as the training set. |\n",
        "| Applying Grid Search                           | Use Grid Search to find the best combination of hyperparameters for the SVM model. Hyperparameters are parameters that are set before the model is trained, and they significantly impact the model's performance. Grid Search systematically tries different combinations of hyperparameter values and evaluates the model's performance using k-Fold Cross Validation. The combination that results in the best performance is selected as the optimal set of hyperparameters for the model. |\n",
        "| Visualising the Test set results               | Visualize the SVM model's performance on the test set using a contour plot. The contour plot shows the decision boundary of the model, which separates the different classes in the dataset. This visualization helps to understand how well the SVM model is classifying the data. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "\n",
        "# Training the Kernel SVM model on the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='rbf', random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean() * 100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std() * 100))\n",
        "\n",
        "# Applying Grid Search to find the best model and the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
        "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
        "grid_search = GridSearchCV(estimator=classifier,\n",
        "                           param_grid=parameters,\n",
        "                           scoring='accuracy',\n",
        "                           cv=10,\n",
        "                           n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy * 100))\n",
        "print(\"Best Parameters:\", best_parameters)\n",
        "\n",
        "# Visualising the Test set results\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}