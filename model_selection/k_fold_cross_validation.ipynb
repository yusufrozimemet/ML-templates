{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN0tzF04XXzPPKRN0eMpb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/model_selection/k_fold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                           | Description                                                                                                                                         |\n",
        "|------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Feature Scaling                                | Apply feature scaling to standardize the features in the dataset. Feature scaling ensures that all features have the same scale, which can help improve the performance and convergence of the SVM model. |\n",
        "| Training the Kernel SVM model                  | Train the SVM model with a non-linear kernel (RBF kernel) on the training set. The RBF kernel allows the SVM to handle non-linearly separable data and capture complex relationships between features. |\n",
        "| Making the Confusion Matrix                    | Evaluate the performance of the trained SVM model on the test set by creating a confusion matrix. The confusion matrix shows the number of correct and incorrect predictions for each class. |\n",
        "| Applying k-Fold Cross Validation               | Perform k-Fold Cross Validation to estimate the model's performance on unseen data. The dataset is divided into 'k' subsets (folds), and the model is trained and tested 'k' times, each time using a different fold as the test set and the remaining as the training set. |\n",
        "| Visualising the Test set results               | Visualize the SVM model's performance on the test set using a contour plot. The contour plot shows the decision boundary of the model, which separates the different classes in the dataset. This visualization helps to understand how well the SVM model is classifying the data. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "\n",
        "# Training the Kernel SVM model on the Training set\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "\n",
        "# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean() * 100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std() * 100))\n",
        "\n",
        "# Visualising the Test set results\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}