{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwxE22orO+QALSqndJRSin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/model_selection/xg_boost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                           | Description                                                                                                                                         |\n",
        "|------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| XGBoost                                        | XGBoost is an advanced and efficient implementation of gradient boosting. It is a popular machine learning algorithm known for its high performance and ability to handle complex tasks. |\n",
        "| Training XGBoost on the Training set           | Train the XGBoost classifier on the training set. The XGBoost model will learn from the training data to make predictions and capture the underlying patterns in the data. |\n",
        "| Making the Confusion Matrix                    | Evaluate the performance of the trained XGBoost model on the test set by creating a confusion matrix. The confusion matrix shows the number of correct and incorrect predictions for each class. |\n",
        "| Applying k-Fold Cross Validation               | Perform k-Fold Cross Validation to estimate the model's performance on unseen data. The dataset is divided into 'k' subsets (folds), and the XGBoost model is trained and tested 'k' times, each time using a different fold as the test set and the remaining as the training set. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training XGBoost on the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "\n",
        "# Applying k-Fold Cross Validation\n",
        "\n"
      ],
      "metadata": {
        "id": "4llK0EaMherw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}