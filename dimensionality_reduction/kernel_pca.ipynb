{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+NjYHdHG1nMDLRbTtV+RN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/dimensionality_reduction/kernel_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                              | Explanation                                                                                                                     |\n",
        "|---------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|\n",
        "| 1. Applying Kernel PCA                            | Kernel Principal Component Analysis (Kernel PCA) is a non-linear dimensionality reduction technique that uses the \"kernel trick\" to implicitly map the data into a higher-dimensional space. It transforms the feature space into a lower-dimensional space while preserving the non-linear relationships in the data. In this step, we specify the desired number of kernel principal components, which is set to 2 in this case. We also select the kernel function (e.g., 'rbf' for radial basis function) to define the similarity between data points. |\n",
        "| 2. Training the Logistic Regression model        | After applying Kernel PCA and obtaining the transformed feature vectors in the training set, we train a Logistic Regression model on this reduced data. Logistic Regression is a popular classification algorithm used for binary or multiclass classification tasks. It learns to separate the data into different classes based on the input features. |\n",
        "| 3. Making the Confusion Matrix                    | The Confusion Matrix is a table used to evaluate the performance of a classification model. It shows the number of true positives, true negatives, false positives, and false negatives. It helps assess how well the model predicts the classes on the test set. |\n",
        "| 4. Visualising the Test set results (Decision boundary) | To visualize how the model separates the data into classes after applying Kernel PCA, we create a grid of points spanning the range of the kernel principal components. We then apply the trained classifier to each point on the grid to predict the class and create a contour plot to visualize the decision boundary. This allows us to observe how well the model has learned the non-linear relationships in the data. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already split your dataset into X_train, X_test, y_train, and y_test\n",
        "\n",
        "# Applying Kernel PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components=2, kernel='rbf')\n",
        "X_train = kpca.fit_transform(X_train)\n",
        "X_test = kpca.transform(X_test)\n",
        "\n",
        "# Training the Logistic Regression model on the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix (Not shown in the provided code)\n",
        "# To make predictions and evaluate the model's performance on the test set\n",
        "\n",
        "# Visualising the Test set results (Not shown in the provided code)\n",
        "# To visualize how the model separates the data into classes after Kernel PCA\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0sak9Pno7dS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}