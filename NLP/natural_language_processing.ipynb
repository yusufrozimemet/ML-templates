{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOcZ4lEAoFFPw1UfYxaGMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoseforaz0990/ML-templates/blob/main/NLP/natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                                          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
        "|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Importing the libraries                      | Import the required libraries for text preprocessing and machine learning. This includes the `re` library for regular expressions, `nltk` for natural language processing tasks, `stopwords` from NLTK to remove common words, `PorterStemmer` for word stemming, `CountVectorizer` from scikit-learn for Bag of Words representation, and `GaussianNB` from scikit-learn for the Naive Bayes classifier.                                                                                                                                     |\n",
        "| Importing the dataset                        | Load the dataset containing the text reviews and their corresponding sentiment labels. This dataset will be used to train and test the Naive Bayes classifier.                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
        "| Cleaning the texts                           | Preprocess the text reviews to remove any characters other than alphabets, convert text to lowercase, tokenize the text into individual words, perform word stemming to reduce words to their root form, and remove common English stopwords to focus on important words for sentiment analysis. The cleaned text reviews are stored in the `corpus` list.                                                                                                                                                                                                                                                                                             |\n",
        "| Creating the Bag of Words model              | Create a Bag of Words representation of the preprocessed text reviews using CountVectorizer. The Bag of Words model converts the text data into a numerical format, representing the frequency of each word in each review. The `max_features` parameter specifies the maximum number of words (features) to be included in the model.                                                                                                                                                                                                                                                                              |\n",
        "| Splitting the dataset into Training and Test | Split the dataset into the training set and the test set. The training set will be used to train the Naive Bayes classifier, and the test set will be used to evaluate its performance.                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
        "| Training the Naive Bayes model               | Train the Naive Bayes classifier on the training set, using the Bag of Words representation of the text reviews and their corresponding sentiment labels. The Naive Bayes algorithm learns the probability distribution of words given a sentiment label and uses it to classify new reviews based on their word frequencies.                                                                                                                                                                                                                                                                                   |\n",
        "| Predicting the Test set results              | Use the trained Naive Bayes classifier to predict the sentiment labels for the test set reviews. The predicted results are stored in the `y_pred` variable.                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
        "| Making the Confusion Matrix                  | The confusion matrix can be computed to evaluate the performance of the classifier. However, the code snippet for this part is not provided in the original code. A confusion matrix allows us to analyze the accuracy of the classifier's predictions and understand the number of true positives, true negatives, false positives, and false negatives. It helps in assessing the overall model performance and identifying any biases or issues in the classification process. |\n"
      ],
      "metadata": {
        "id": "5fBsP7-bjOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Importing the dataset (dataset is not provided in the code, assuming it's already loaded)\n",
        "\n",
        "# Cleaning the texts\n",
        "corpus = []\n",
        "for i in range(0, 1000):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = PorterStemmer()\n",
        "    all_stopwords = stopwords.words('english')\n",
        "    all_stopwords.remove('not')\n",
        "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "# Creating the Bag of Words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set (assuming they are already prepared)\n",
        "\n",
        "# Training the Naive Bayes model on the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "# Making the Confusion Matrix (assuming y_pred and y_test are available)\n"
      ],
      "metadata": {
        "id": "uH2G2ys4ODFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}